{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"flight_delays.ipynb","provenance":[],"authorship_tag":"ABX9TyM/1dRLw+G3CYIgtI2dBF0g"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"jenr5ZMV66jC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":238},"outputId":"fef3d0f2-e1e6-4555-9e13-a149a2b8dbd5","executionInfo":{"status":"ok","timestamp":1588214410128,"user_tz":-420,"elapsed":80829,"user":{"displayName":"Imam Hanafi Sistem Informasi","photoUrl":"","userId":"07450488865621521207"}}},"source":["!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","!wget -q http://apache.osuosl.org/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n","!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n","\n","!pip install -q findspark\n","!pip install pyspark\n","\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\""],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting pyspark\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/5a/271c416c1c2185b6cb0151b29a91fff6fcaed80173c8584ff6d20e46b465/pyspark-2.4.5.tar.gz (217.8MB)\n","\u001b[K     |████████████████████████████████| 217.8MB 62kB/s \n","\u001b[?25hCollecting py4j==0.10.7\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n","\u001b[K     |████████████████████████████████| 204kB 44.2MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-2.4.5-py2.py3-none-any.whl size=218257927 sha256=65bfe42b3f6aa1e885c2e8268a8bc2fc64d3bfbe92dd98b74dd89966ae2d0315\n","  Stored in directory: /root/.cache/pip/wheels/bf/db/04/61d66a5939364e756eb1c1be4ec5bdce6e04047fc7929a3c3c\n","Successfully built pyspark\n","Installing collected packages: py4j, pyspark\n","Successfully installed py4j-0.10.7 pyspark-2.4.5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bsciwMQR7pV1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"28df4f88-6aca-4fcf-c4d9-a47124fb35df","executionInfo":{"status":"ok","timestamp":1588214706845,"user_tz":-420,"elapsed":4050,"user":{"displayName":"Imam Hanafi Sistem Informasi","photoUrl":"","userId":"07450488865621521207"}}},"source":["!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java"],"execution_count":3,"outputs":[{"output_type":"stream","text":["update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java to provide /usr/bin/java (java) in manual mode\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6eojYk2f-cio","colab_type":"text"},"source":["!java -version"]},{"cell_type":"markdown","metadata":{"id":"ivymyZp5_BVL","colab_type":"text"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","metadata":{"id":"-st7bRO5_tdH","colab_type":"code","colab":{}},"source":["import requests\n","file_url = \"http://www.rdatasciencecases.org/Data/Airline/2007.csv.bz2\"\n","\n","r = requests.get(file_url, stream = True)\n","\n","with open(\"/content/gdrive/My Drive/Colab Datasets/2007.csv.bz2\", \"wb\") as file:\n","  for block in r.iter_content(chunk_size = 1024):\n","    if block:\n","      file.write(block)\n","\n","\n","file_url = \"http://www.rdatasciencecases.org/Data/Airline/2008.csv.bz2\"\n","\n","r = requests.get(file_url, stream = True)\n","\n","with open(\"/content/gdrive/My Drive/Colab Datasets/2008.csv.bz2\", \"wb\") as file:\n","  for block in r.iter_content(chunk_size = 1024):\n","    if block:\n","      file.write(block)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rrag1FofBinp","colab_type":"code","colab":{}},"source":["from pyspark import SparkContext\n","from pyspark.sql import SparkSession\n","\n","from pyspark.ml import Pipeline\n","from pyspark.ml.classification import RandomForestClassifier\n","from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer, VectorAssembler\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n","\n","from pyspark.sql.functions import isnan, when, count, col"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4K35KeCGBzH9","colab_type":"code","colab":{}},"source":["CSV_2007= \"/content/gdrive/My Drive/Colab Datasets/2007.csv.bz2\" \n","CSV_2008= \"/content/gdrive/My Drive/Colab Datasets/2008.csv.bz2\"\n","APP_NAME = \"Flight Delays\"\n","SPARK_URL = \"local[*]\"\n","RANDOM_SEED = 141109\n","TRAINING_DATA_RATIO = 0.7\n","RF_NUM_TREES = 8\n","RF_MAX_DEPTH = 4\n","RF_NUM_BINS = 32"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kOh7hgpcCbS9","colab_type":"code","colab":{}},"source":["# Connect to the Spark server\n","\n","spark = SparkSession.builder.appName(APP_NAME).master(SPARK_URL).getOrCreate()\n","\n","# Load datasets\n","\n","df_2007 = spark.read.options(header=\"true\",inferschema = \"true\").csv(CSV_2007)\n","df_2008 = spark.read.options(header=\"true\",inferschema = \"true\").csv(CSV_2008)\n","\n","# We concatenate both datasets\n","\n","df = df_2007.unionAll(df_2008)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ucA7DU5vDCF-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"87066b9e-f4a3-4d22-ea95-615521ec499a","executionInfo":{"status":"ok","timestamp":1588216008634,"user_tz":-420,"elapsed":56738,"user":{"displayName":"Imam Hanafi Sistem Informasi","photoUrl":"","userId":"07450488865621521207"}}},"source":["# What's the data shape before starting cleaning ?\n","\n","print(f\"The shape is {df.count():d} rows by {len(df.columns):d} columns.\")"],"execution_count":10,"outputs":[{"output_type":"stream","text":["The shape is 14462943 rows by 29 columns.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Zn86v2_sDYu0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"aa49bdf2-ba4e-441e-bab2-ed0694b34611","executionInfo":{"status":"ok","timestamp":1588216398791,"user_tz":-420,"elapsed":354373,"user":{"displayName":"Imam Hanafi Sistem Informasi","photoUrl":"","userId":"07450488865621521207"}}},"source":["# What's the number of null values ?\n","\n","null_counts = df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) \n","                         for c in df.columns]).toPandas().to_dict(orient='records')\n","\n","print(f\"We have {sum(null_counts[0].values()):d} null values in this dataset.\")"],"execution_count":11,"outputs":[{"output_type":"stream","text":["We have 14248147 null values in this dataset.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gpYylMXAFGuH","colab_type":"code","colab":{}},"source":["# Drop null columns and inputs ?\n","\n","df = df.drop(df.CancellationCode)\n","df = df.na.drop()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oFpv1rQ_FU1q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"27abdee5-5627-4fd6-ab27-c9e4e0d27f76","executionInfo":{"status":"ok","timestamp":1588216919512,"user_tz":-420,"elapsed":357862,"user":{"displayName":"Imam Hanafi Sistem Informasi","photoUrl":"","userId":"07450488865621521207"}}},"source":["# Confirm there are no null values\n","\n","null_counts = df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) \n","                         for c in df.columns]).toPandas().to_dict(orient='records')\n","\n","print(f\"We have {sum(null_counts[0].values()):d} null values in this dataset.\")"],"execution_count":13,"outputs":[{"output_type":"stream","text":["We have 0 null values in this dataset.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RjSpsKX5G64X","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"9c34a0e5-846d-43c9-99ea-0ed074d24122","executionInfo":{"status":"ok","timestamp":1588217103804,"user_tz":-420,"elapsed":133051,"user":{"displayName":"Imam Hanafi Sistem Informasi","photoUrl":"","userId":"07450488865621521207"}}},"source":["# What's the data shape after cleaning ?\n","\n","print(f\"The shape is {df.count():d} rows by {len(df.columns):d} columns.\")"],"execution_count":14,"outputs":[{"output_type":"stream","text":["The shape is 14379556 rows by 28 columns.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gzSkf0dpHi8b","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":493},"outputId":"bf138886-c5c3-48fc-c205-33b6a302d138","executionInfo":{"status":"ok","timestamp":1588217135952,"user_tz":-420,"elapsed":1618,"user":{"displayName":"Imam Hanafi Sistem Informasi","photoUrl":"","userId":"07450488865621521207"}}},"source":["# What are the column's type ?\n","\n","df.dtypes"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('Year', 'int'),\n"," ('Month', 'int'),\n"," ('DayofMonth', 'int'),\n"," ('DayOfWeek', 'int'),\n"," ('DepTime', 'string'),\n"," ('CRSDepTime', 'int'),\n"," ('ArrTime', 'string'),\n"," ('CRSArrTime', 'int'),\n"," ('UniqueCarrier', 'string'),\n"," ('FlightNum', 'int'),\n"," ('TailNum', 'string'),\n"," ('ActualElapsedTime', 'string'),\n"," ('CRSElapsedTime', 'string'),\n"," ('AirTime', 'string'),\n"," ('ArrDelay', 'string'),\n"," ('DepDelay', 'string'),\n"," ('Origin', 'string'),\n"," ('Dest', 'string'),\n"," ('Distance', 'int'),\n"," ('TaxiIn', 'string'),\n"," ('TaxiOut', 'string'),\n"," ('Cancelled', 'int'),\n"," ('Diverted', 'int'),\n"," ('CarrierDelay', 'string'),\n"," ('WeatherDelay', 'string'),\n"," ('NASDelay', 'string'),\n"," ('SecurityDelay', 'string'),\n"," ('LateAircraftDelay', 'string')]"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"sjGw5BnFHzzI","colab_type":"code","colab":{}},"source":["# Create list of feature columns\n","\n","feature_cols = ['Year', 'Month', 'DayofMonth', 'DayOfWeek', 'CRSDepTime', \n","                'CRSArrTime', 'FlightNum', 'Distance', 'Diverted']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UO23D60pH9VR","colab_type":"code","colab":{}},"source":["# Generate and create our new feature vector column\n","\n","df = VectorAssembler(inputCols=feature_cols, outputCol=\"features\").transform(df)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"v-Jf6nlnIHE_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"e89ce8fd-4ab0-416c-c481-46a1aa60b497","executionInfo":{"status":"ok","timestamp":1588217284029,"user_tz":-420,"elapsed":2012,"user":{"displayName":"Imam Hanafi Sistem Informasi","photoUrl":"","userId":"07450488865621521207"}}},"source":["# Select input columns\n","\n","df.select(\"Cancelled\", \"features\").show(5)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["+---------+--------------------+\n","|Cancelled|            features|\n","+---------+--------------------+\n","|        0|[2007.0,1.0,1.0,1...|\n","|        0|[2007.0,1.0,1.0,1...|\n","|        0|[2007.0,1.0,1.0,1...|\n","|        0|[2007.0,1.0,1.0,1...|\n","|        0|[2007.0,1.0,1.0,1...|\n","+---------+--------------------+\n","only showing top 5 rows\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pyBh4CMkIQ0U","colab_type":"code","colab":{}},"source":["# Build the training indexers\n","\n","# Generate a labelIndexer\n","labelIndexer = StringIndexer(inputCol=\"Cancelled\", outputCol=\"indexedLabel\").fit(df)\n","\n","# Generate the indexed feature vector\n","featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(df)\n","    \n","# Split the data into training and tests sets\n","(trainingData, testData) = df.randomSplit([TRAINING_DATA_RATIO, 1 - TRAINING_DATA_RATIO])\n","\n","# Train the RandomForest model\n","rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=RF_NUM_TREES)\n","\n","# Chain indexers and the forest models in a Pipeline\n","pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IDaq4pxgJo3N","colab_type":"code","colab":{}},"source":["# Train the model\n","\n","model = pipeline.fit(trainingData)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nW_CFHHzNgbZ","colab_type":"code","colab":{}},"source":["# Make predictions\n","\n","predictions = model.transform(testData)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-JPWic-ANquX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"ad902b3c-ed90-46b1-8e9c-4b754f7c37a1","executionInfo":{"status":"ok","timestamp":1588219177633,"user_tz":-420,"elapsed":436398,"user":{"displayName":"Imam Hanafi Sistem Informasi","photoUrl":"","userId":"07450488865621521207"}}},"source":["# Select prediction, true label and compute test error\n","evaluator = MulticlassClassificationEvaluator(\n","    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n","accuracy = evaluator.evaluate(predictions)\n","\n","print(f\"Test Error = {(1.0 - accuracy):g}\")\n","print(f\"Accuracy = {accuracy:g}\")"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Test Error = 0.0149549\n","Accuracy = 0.985045\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"25HOEEBdPdCr","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}